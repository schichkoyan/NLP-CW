{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Sentiment Analysis from Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            (label, text) = parse_data_line(line)\n",
    "            raw_data.append((text, label))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label) in raw_data[:num_training_samples]:\n",
    "        train_data.append((to_feature_vector(pre_process(text)),label))\n",
    "    for (text, label) in raw_data[num_training_samples:]:\n",
    "        test_data.append((to_feature_vector(pre_process(text)),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_line(data_line):\n",
    "    label= data_line[1]\n",
    "    text = data_line[2]\n",
    "    return (label, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "\n",
    "# Input: a string of one statement\n",
    "def pre_process(text):\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Lowercasing\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Removing special characters\n",
    "    words = [re.sub(r'[^A-Za-z0-9]', '', word) for word in words]\n",
    "\n",
    "    # Handling negations\n",
    "    negations = set([\"not\", \"no\", \"never\"])\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in negations and i < len(words) - 1:\n",
    "            words[i + 1] = \"not_\" + words[i + 1]\n",
    "\n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Expand contractions\n",
    "    contractions = {\"don't\": \"do not\", \"can't\": \"cannot\", \"won't\": \"will not\"}\n",
    "    words = [contractions.get(word, word) for word in words]\n",
    "\n",
    "    # Replace numbers with a placeholder\n",
    "    words = ['number' if word.isdigit() else word for word in words]\n",
    "\n",
    "    # Sentiment analysis\n",
    "    sentiment = TextBlob(text).sentiment\n",
    "    words.append('positive' if sentiment.polarity > 0 else 'negative' if sentiment.polarity < 0 else 'neutral')\n",
    "\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import ngrams\n",
    "\n",
    "global_feature_dict = {}  # A global dictionary of features\n",
    "\n",
    "def to_feature_vector(tokens):\n",
    "    # Create a dictionary to store features\n",
    "    feature_vector = {}\n",
    "    \n",
    "    # Iterate through each token in the list of tokens\n",
    "    for token in tokens:\n",
    "        if token not in global_feature_dict:\n",
    "            global_feature_dict[token] = 0\n",
    "        global_feature_dict[token] += 1\n",
    "\n",
    "        if token not in feature_vector:\n",
    "            feature_vector[token] = 0\n",
    "        feature_vector[token] += 1\n",
    "\n",
    "    \"\"\"#TF-IDF\n",
    "    text = \" \".join(tokens)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    feature_vector.update({feature_names[i]: tfidf_matrix[0, i] for i in range(len(feature_names))})\"\"\"\n",
    "\n",
    "    #N-grams (bigrams and trigrams)\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "    feature_vector.update({\"bigram_\" + \"_\".join(bigram): 1 for bigram in bigrams})\n",
    "    feature_vector.update({\"trigram_\" + \"_\".join(trigram): 1 for trigram in trigrams})\n",
    "\n",
    "    #Document Length\n",
    "    feature_vector[\"document_length\"] = len(tokens)\n",
    "\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "\n",
    "def train_classifier(data, C=1.0, class_weight=None):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline = Pipeline([('svc', LinearSVC(C=C, class_weight=class_weight))])\n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def cross_validate(dataset, folds,test_size=0.2):\n",
    "    cv_results = []\n",
    "    fold_size = int(len(dataset) / folds) + 1\n",
    "\n",
    "    for i in range(0, len(dataset), int(fold_size)):\n",
    "        # Train classifier on current fold (training set)\n",
    "        training_data = dataset[i:i + fold_size]\n",
    "\n",
    "        # Evaluate classifier on remaining folds (test set)\n",
    "        testing_data = []\n",
    "        for j in range(0, folds):\n",
    "            if j == i:\n",
    "                continue\n",
    "            testing_data.extend(dataset[j * fold_size:(j + 1) * fold_size])\n",
    "\n",
    "        # Train and evaluate the classifier\n",
    "        classifier = train_classifier(training_data,C=10,class_weight='balanced')\n",
    "\n",
    "        testing_data_dicts = []\n",
    "\n",
    "        for feature_vector, label in testing_data:\n",
    "            testing_data_dicts.append({feature: value for feature, value in feature_vector.items()})\n",
    "            \n",
    "        predicted_labels = predict_labels(testing_data_dicts, classifier)\n",
    "        true_labels = [label for _, label in testing_data]\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, predicted_labels)\n",
    "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        cv_results.append((precision, recall, fscore, accuracy))\n",
    "\n",
    "        # Calculate average performance across folds\n",
    "        avg_precision = sum(precision) / folds\n",
    "        avg_recall = sum(recall) / folds\n",
    "        avg_fscore = sum(fscore) / folds\n",
    "        avg_accuracy = accuracy\n",
    "\n",
    "        print(\"Average Precision: {:.2f}\".format(avg_precision))\n",
    "        print(\"Average Recall: {:.2f}\".format(avg_recall))\n",
    "        print(\"Average F-Score: {:.2f}\".format(avg_fscore))\n",
    "        print(\"Average Accuracy: {:.2f}\".format(avg_accuracy))\n",
    "\n",
    "     # Create a Pandas DataFrame\n",
    "    results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "     # Rename the columns for better readability\n",
    "    results_df.columns = ['Precision', 'Recall', 'F-Score','Accuracy']\n",
    "\n",
    "    # Print the detailed results\n",
    "    print(\"\\nCross-Validation Results:\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 33540 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "After split, 33540 rawData, 26832 trainData, 6708 testData\n",
      "Training Samples: \n",
      "26832\n",
      "Features: \n",
      "50594\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# loading reviews\n",
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'sentiment-dataset.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sako/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.16\n",
      "Average Recall: 0.15\n",
      "Average F-Score: 0.15\n",
      "Average Accuracy: 0.80\n",
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sako/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.16\n",
      "Average Recall: 0.14\n",
      "Average F-Score: 0.14\n",
      "Average Accuracy: 0.77\n",
      "Training Classifier...\n",
      "Average Precision: 0.16\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.82\n",
      "Training Classifier...\n",
      "Average Precision: 0.16\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.83\n",
      "Training Classifier...\n",
      "Average Precision: 0.16\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.83\n",
      "Training Classifier...\n",
      "Average Precision: 0.16\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.83\n",
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sako/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.17\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.83\n",
      "Training Classifier...\n",
      "Average Precision: 0.17\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.83\n",
      "Training Classifier...\n",
      "Average Precision: 0.17\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.83\n",
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sako/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.17\n",
      "Average Recall: 0.16\n",
      "Average F-Score: 0.16\n",
      "Average Accuracy: 0.84\n",
      "\n",
      "Cross-Validation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.7923383878691141, 0.8042274786109713]</td>\n",
       "      <td>[0.5864146485528647, 0.9170439329209973]</td>\n",
       "      <td>[0.6739986422267481, 0.8569385687898468]</td>\n",
       "      <td>0.801143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.801195219123506, 0.758802494039978]</td>\n",
       "      <td>[0.43326510826241516, 0.9431306627158242]</td>\n",
       "      <td>[0.562399496609103, 0.8409847310789869]</td>\n",
       "      <td>0.766734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.7630568803070839, 0.8506717850287908]</td>\n",
       "      <td>[0.7066681029839491, 0.8839250099720782]</td>\n",
       "      <td>[0.7337807606263983, 0.8669796557120502]</td>\n",
       "      <td>0.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.7810354857475277, 0.8590776991829796]</td>\n",
       "      <td>[0.7231498438004955, 0.8927574220753319]</td>\n",
       "      <td>[0.7509788566953798, 0.8755938076342702]</td>\n",
       "      <td>0.834079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.8073997679515277, 0.8416775884665793]</td>\n",
       "      <td>[0.6746741355165357, 0.9148669439854122]</td>\n",
       "      <td>[0.7350938967136151, 0.8767474879860201]</td>\n",
       "      <td>0.831768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.8000499875031242, 0.8469994689325544]</td>\n",
       "      <td>[0.6896477431864699, 0.9088267137728645]</td>\n",
       "      <td>[0.7407578825571304, 0.8768245416311607]</td>\n",
       "      <td>0.832998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.8135103167301879, 0.8390989959943818]</td>\n",
       "      <td>[0.6668102983949155, 0.9191406917773093]</td>\n",
       "      <td>[0.7328913094956193, 0.877297944087893]</td>\n",
       "      <td>0.831843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.8087326120556414, 0.842458569330816]</td>\n",
       "      <td>[0.6763977162555208, 0.9153797937204399]</td>\n",
       "      <td>[0.736669208658415, 0.8774066690335091]</td>\n",
       "      <td>0.832700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.814257161892072, 0.8358772701402184]</td>\n",
       "      <td>[0.6583001184961758, 0.9205652743746082]</td>\n",
       "      <td>[0.7280200142959257, 0.8761796290270094]</td>\n",
       "      <td>0.829830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.8128300914594873, 0.8440925061618333]</td>\n",
       "      <td>[0.6797371539373047, 0.9172032594449826]</td>\n",
       "      <td>[0.7403496421447847, 0.879130482276476]</td>\n",
       "      <td>0.835048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Precision  \\\n",
       "0  [0.7923383878691141, 0.8042274786109713]   \n",
       "1    [0.801195219123506, 0.758802494039978]   \n",
       "2  [0.7630568803070839, 0.8506717850287908]   \n",
       "3  [0.7810354857475277, 0.8590776991829796]   \n",
       "4  [0.8073997679515277, 0.8416775884665793]   \n",
       "5  [0.8000499875031242, 0.8469994689325544]   \n",
       "6  [0.8135103167301879, 0.8390989959943818]   \n",
       "7   [0.8087326120556414, 0.842458569330816]   \n",
       "8   [0.814257161892072, 0.8358772701402184]   \n",
       "9  [0.8128300914594873, 0.8440925061618333]   \n",
       "\n",
       "                                      Recall  \\\n",
       "0   [0.5864146485528647, 0.9170439329209973]   \n",
       "1  [0.43326510826241516, 0.9431306627158242]   \n",
       "2   [0.7066681029839491, 0.8839250099720782]   \n",
       "3   [0.7231498438004955, 0.8927574220753319]   \n",
       "4   [0.6746741355165357, 0.9148669439854122]   \n",
       "5   [0.6896477431864699, 0.9088267137728645]   \n",
       "6   [0.6668102983949155, 0.9191406917773093]   \n",
       "7   [0.6763977162555208, 0.9153797937204399]   \n",
       "8   [0.6583001184961758, 0.9205652743746082]   \n",
       "9   [0.6797371539373047, 0.9172032594449826]   \n",
       "\n",
       "                                    F-Score  Accuracy  \n",
       "0  [0.6739986422267481, 0.8569385687898468]  0.801143  \n",
       "1   [0.562399496609103, 0.8409847310789869]  0.766734  \n",
       "2  [0.7337807606263983, 0.8669796557120502]  0.822600  \n",
       "3  [0.7509788566953798, 0.8755938076342702]  0.834079  \n",
       "4  [0.7350938967136151, 0.8767474879860201]  0.831768  \n",
       "5  [0.7407578825571304, 0.8768245416311607]  0.832998  \n",
       "6   [0.7328913094956193, 0.877297944087893]  0.831843  \n",
       "7   [0.736669208658415, 0.8774066690335091]  0.832700  \n",
       "8  [0.7280200142959257, 0.8761796290270094]  0.829830  \n",
       "9   [0.7403496421447847, 0.879130482276476]  0.835048  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(train_data, 10)  # will work and output overall performance of p, r, f-score when cv implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# a function to make the confusion matrix readable and pretty\n",
    "def confusion_matrix_heatmap(y_test, preds, labels):\n",
    "    \"\"\"Function to plot a confusion matrix\"\"\"\n",
    "    # pass labels to the confusion matrix function to ensure right order\n",
    "    # cm = metrics.confusion_matrix(y_test, preds, labels)\n",
    "    cm = metrics.confusion_matrix(y_test, preds, labels=labels)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels( labels, rotation=45)\n",
    "    ax.set_yticklabels( labels)\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm)):\n",
    "            text = ax.text(j, i, cm[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # fix for mpl bug that cuts off top/bottom of seaborn viz:\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "    plt.show() # ta-da!\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(classifier, test_data):\n",
    "    \"\"\"Perform error analysis on a simple train-test split.\"\"\"\n",
    "    test_samples, true_labels = zip(*test_data)\n",
    "    predicted_labels = predict_labels(test_samples, classifier)\n",
    "\n",
    "    # Create a list of tuples \n",
    "    errors = [(test_samples[i], true_labels[i], predicted_labels[i]) for i in range(len(test_samples)) if true_labels[i] != predicted_labels[i]]\n",
    "\n",
    "    # Print false positives and false negatives for the positive label\n",
    "    with open('error_analysis2.txt', 'w') as f:\n",
    "        f.write(\"False Positives (Predicted Positive, Actual Negative):\\n\")\n",
    "        for sample, true_label, predicted_label in errors:\n",
    "            if predicted_label == 'positive' and true_label == 'negative':\n",
    "                f.write(f\"Sample: {sample}, Actual: {true_label}, Predicted: {predicted_label}\\n\")\n",
    "\n",
    "        f.write(\"\\nFalse Negatives (Predicted Negative, Actual Positive):\\n\")\n",
    "        for sample, true_label, predicted_label in errors:\n",
    "            if predicted_label == 'negative' and true_label == 'positive':\n",
    "                f.write(f\"Sample: {sample}, Actual: {true_label}, Predicted: {predicted_label}\\n\")\n",
    "\n",
    "    print(\"Error analysis written to error_analysis2.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sako/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analysis written to error_analysis2.txt\n"
     ]
    }
   ],
   "source": [
    "classifier = train_classifier(train_data)  # train on the entire training set for simplicity\n",
    "test_samples, true_labels = zip(*test_data)\n",
    "predicted_labels = predict_labels(test_samples, classifier)\n",
    "\n",
    "error_analysis(classifier, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_heatmap(true_labels, predicted_labels, ['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'tomorrow': 1, 'releas': 1, '58th': 1, 'episod': 1, 'hsonair': 1, 'profil': 1, 'alissadossanto': 1, 'talk': 1, 'storytel': 1, 'beyonc': 1, 'positive': 1, 'bigram_tomorrow_releas': 1, 'bigram_releas_58th': 1, 'bigram_58th_episod': 1, 'bigram_episod_hsonair': 1, 'bigram_hsonair_profil': 1, 'bigram_profil_alissadossanto': 1, 'bigram_alissadossanto_talk': 1, 'bigram_talk_storytel': 1, 'bigram_storytel_beyonc': 1, 'bigram_beyonc_positive': 1, 'trigram_tomorrow_releas_58th': 1, 'trigram_releas_58th_episod': 1, 'trigram_58th_episod_hsonair': 1, 'trigram_episod_hsonair_profil': 1, 'trigram_hsonair_profil_alissadossanto': 1, 'trigram_profil_alissadossanto_talk': 1, 'trigram_alissadossanto_talk_storytel': 1, 'trigram_talk_storytel_beyonc': 1, 'trigram_storytel_beyonc_positive': 1, 'document_length': 11}, 'positive')\n",
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sako/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n",
      "Precision: 0.870275\n",
      "Recall: 0.871348\n",
      "F Score:0.869553\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of your classifier by training on all the traning data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    print(test_data[0])   # have a look at the first test data instance\n",
    "    classifier = train_classifier(train_data)  # train the classifier\n",
    "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
    "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
    "    print(\"Done training!\")\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
